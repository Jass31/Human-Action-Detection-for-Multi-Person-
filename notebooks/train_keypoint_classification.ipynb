{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jashtandel/SEM6/Approach2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data unique labels:\n",
      "label\n",
      "punch    1132\n",
      "kick     1078\n",
      "stand    1050\n",
      "jump     1026\n",
      "run       966\n",
      "walk      954\n",
      "sit       938\n",
      "squat     715\n",
      "wave      702\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data unique labels:\n",
      "label\n",
      "sit      764\n",
      "stand    535\n",
      "squat    442\n",
      "jump     354\n",
      "kick     336\n",
      "punch    336\n",
      "wave     239\n",
      "run      222\n",
      "walk     144\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training data unique labels (with repr):\n",
      "'jump'\n",
      "'kick'\n",
      "'punch'\n",
      "'run'\n",
      "'sit'\n",
      "'squat'\n",
      "'stand'\n",
      "'walk'\n",
      "'wave'\n",
      "\n",
      "Test data unique labels (with repr):\n",
      "'jump'\n",
      "'kick'\n",
      "'punch'\n",
      "'run'\n",
      "'sit'\n",
      "'squat'\n",
      "'stand'\n",
      "'walk'\n",
      "'wave'\n",
      "\n",
      "Unique labels after cleaning:\n",
      "Training: ['jump' 'kick' 'punch' 'run' 'sit' 'squat' 'stand' 'walk' 'wave']\n",
      "Testing: ['jump' 'kick' 'punch' 'run' 'sit' 'squat' 'stand' 'walk' 'wave']\n",
      "\n",
      "Encoded labels:\n",
      "Number of classes: 9\n",
      "Classes: ['jump' 'kick' 'punch' 'run' 'sit' 'squat' 'stand' 'walk' 'wave']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.classification_keypoint import AngleLSTMNet, AngleFeatureExtractor\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('/Users/jashtandel/SEM6/Approach2/datasets/train_action_pose_keypoint.csv')\n",
    "test_data = pd.read_csv('/Users/jashtandel/SEM6/Approach2/datasets/test_action_pose_keypoint.csv')\n",
    "\n",
    "# Debug: Print unique labels and their counts\n",
    "print(\"Training data unique labels:\")\n",
    "print(train_data['label'].value_counts())\n",
    "print(\"\\nTest data unique labels:\")\n",
    "print(test_data['label'].value_counts())\n",
    "\n",
    "# Debug: Check for whitespace and case issues\n",
    "print(\"\\nTraining data unique labels (with repr):\")\n",
    "for label in train_data['label'].unique():\n",
    "    print(repr(label))\n",
    "print(\"\\nTest data unique labels (with repr):\")\n",
    "for label in test_data['label'].unique():\n",
    "    print(repr(label))\n",
    "\n",
    "# Clean the labels (remove leading/trailing whitespace and convert to lowercase)\n",
    "train_data['label'] = train_data['label'].str.strip().str.lower()\n",
    "test_data['label'] = test_data['label'].str.strip().str.lower()\n",
    "\n",
    "# Get unique labels after cleaning\n",
    "print(\"\\nUnique labels after cleaning:\")\n",
    "print(\"Training:\", train_data['label'].unique())\n",
    "print(\"Testing:\", test_data['label'].unique())\n",
    "\n",
    "# Now proceed with label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
    "test_data['label'] = label_encoder.transform(test_data['label'])\n",
    "\n",
    "print(\"\\nEncoded labels:\")\n",
    "print(\"Number of classes:\", len(label_encoder.classes_))\n",
    "print(\"Classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1006 entries, 0 to 1005\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image_name        1006 non-null   object \n",
      " 1   label             1006 non-null   object \n",
      " 2   nose_x            1006 non-null   float64\n",
      " 3   nose_y            1006 non-null   float64\n",
      " 4   left_eye_x        1006 non-null   float64\n",
      " 5   left_eye_y        1006 non-null   float64\n",
      " 6   right_eye_x       1006 non-null   float64\n",
      " 7   right_eye_y       1006 non-null   float64\n",
      " 8   left_ear_x        1006 non-null   float64\n",
      " 9   left_ear_y        1006 non-null   float64\n",
      " 10  right_ear_x       1006 non-null   float64\n",
      " 11  right_ear_y       1006 non-null   float64\n",
      " 12  left_shoulder_x   1006 non-null   float64\n",
      " 13  left_shoulder_y   1006 non-null   float64\n",
      " 14  right_shoulder_x  1006 non-null   float64\n",
      " 15  right_shoulder_y  1006 non-null   float64\n",
      " 16  left_elbow_x      1006 non-null   float64\n",
      " 17  left_elbow_y      1006 non-null   float64\n",
      " 18  right_elbow_x     1006 non-null   float64\n",
      " 19  right_elbow_y     1006 non-null   float64\n",
      " 20  left_wrist_x      1006 non-null   float64\n",
      " 21  left_wrist_y      1006 non-null   float64\n",
      " 22  right_wrist_x     1006 non-null   float64\n",
      " 23  right_wrist_y     1006 non-null   float64\n",
      " 24  left_hip_x        1006 non-null   float64\n",
      " 25  left_hip_y        1006 non-null   float64\n",
      " 26  right_hip_x       1006 non-null   float64\n",
      " 27  right_hip_y       1006 non-null   float64\n",
      " 28  left_knee_x       1006 non-null   float64\n",
      " 29  left_knee_y       1006 non-null   float64\n",
      " 30  right_knee_x      1006 non-null   float64\n",
      " 31  right_knee_y      1006 non-null   float64\n",
      " 32  left_ankle_x      1006 non-null   float64\n",
      " 33  left_ankle_y      1006 non-null   float64\n",
      " 34  right_ankle_x     1006 non-null   float64\n",
      " 35  right_ankle_y     1006 non-null   float64\n",
      "dtypes: float64(34), object(2)\n",
      "memory usage: 283.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/150\n",
      "Training Loss: 1.4427, Training Acc: 46.81%\n",
      "Validation Loss: 1.2111, Validation Acc: 54.86%\n",
      "Epoch 2/150\n",
      "Training Loss: 1.1575, Training Acc: 57.76%\n",
      "Validation Loss: 1.1307, Validation Acc: 59.93%\n",
      "Epoch 3/150\n",
      "Training Loss: 1.0763, Training Acc: 60.97%\n",
      "Validation Loss: 1.0694, Validation Acc: 61.57%\n",
      "Epoch 4/150\n",
      "Training Loss: 1.0304, Training Acc: 63.15%\n",
      "Validation Loss: 1.1387, Validation Acc: 58.04%\n",
      "Epoch 5/150\n",
      "Training Loss: 1.0007, Training Acc: 64.41%\n",
      "Validation Loss: 1.0482, Validation Acc: 64.26%\n",
      "Epoch 6/150\n",
      "Training Loss: 0.9734, Training Acc: 64.97%\n",
      "Validation Loss: 1.0332, Validation Acc: 65.12%\n",
      "Epoch 7/150\n",
      "Training Loss: 0.9445, Training Acc: 66.29%\n",
      "Validation Loss: 1.0444, Validation Acc: 63.85%\n",
      "Epoch 8/150\n",
      "Training Loss: 0.9244, Training Acc: 67.22%\n",
      "Validation Loss: 1.0135, Validation Acc: 66.16%\n",
      "Epoch 9/150\n",
      "Training Loss: 0.9156, Training Acc: 67.78%\n",
      "Validation Loss: 1.0114, Validation Acc: 64.50%\n",
      "Epoch 10/150\n",
      "Training Loss: 0.8976, Training Acc: 67.84%\n",
      "Validation Loss: 1.0343, Validation Acc: 64.65%\n",
      "Epoch 11/150\n",
      "Training Loss: 0.8850, Training Acc: 69.06%\n",
      "Validation Loss: 1.0079, Validation Acc: 64.06%\n",
      "Epoch 12/150\n",
      "Training Loss: 0.8636, Training Acc: 69.24%\n",
      "Validation Loss: 1.0233, Validation Acc: 65.30%\n",
      "Epoch 13/150\n",
      "Training Loss: 0.8671, Training Acc: 68.70%\n",
      "Validation Loss: 0.9689, Validation Acc: 66.64%\n",
      "Epoch 14/150\n",
      "Training Loss: 0.8588, Training Acc: 69.42%\n",
      "Validation Loss: 1.0071, Validation Acc: 66.16%\n",
      "Epoch 15/150\n",
      "Training Loss: 0.8468, Training Acc: 69.73%\n",
      "Validation Loss: 0.9608, Validation Acc: 67.47%\n",
      "Epoch 16/150\n",
      "Training Loss: 0.8373, Training Acc: 70.44%\n",
      "Validation Loss: 0.9994, Validation Acc: 64.98%\n",
      "Epoch 17/150\n",
      "Training Loss: 0.8570, Training Acc: 69.69%\n",
      "Validation Loss: 0.9544, Validation Acc: 68.06%\n",
      "Epoch 18/150\n",
      "Training Loss: 0.8382, Training Acc: 70.18%\n",
      "Validation Loss: 0.9763, Validation Acc: 67.67%\n",
      "Epoch 19/150\n",
      "Training Loss: 0.8047, Training Acc: 71.14%\n",
      "Validation Loss: 0.9708, Validation Acc: 67.50%\n",
      "Epoch 20/150\n",
      "Training Loss: 0.8102, Training Acc: 71.53%\n",
      "Validation Loss: 0.9397, Validation Acc: 67.53%\n",
      "Epoch 21/150\n",
      "Training Loss: 0.8129, Training Acc: 71.08%\n",
      "Validation Loss: 0.9644, Validation Acc: 65.95%\n",
      "Epoch 22/150\n",
      "Training Loss: 0.8199, Training Acc: 71.50%\n",
      "Validation Loss: 0.9696, Validation Acc: 68.45%\n",
      "Epoch 23/150\n",
      "Training Loss: 0.8011, Training Acc: 71.44%\n",
      "Validation Loss: 0.9886, Validation Acc: 67.17%\n",
      "Epoch 24/150\n",
      "Training Loss: 0.8048, Training Acc: 71.29%\n",
      "Validation Loss: 0.9558, Validation Acc: 67.50%\n",
      "Epoch 25/150\n",
      "Training Loss: 0.8046, Training Acc: 71.70%\n",
      "Validation Loss: 1.0036, Validation Acc: 66.58%\n",
      "Epoch 26/150\n",
      "Training Loss: 0.7916, Training Acc: 71.52%\n",
      "Validation Loss: 0.9853, Validation Acc: 66.64%\n",
      "Epoch 27/150\n",
      "Training Loss: 0.7863, Training Acc: 71.67%\n",
      "Validation Loss: 0.9716, Validation Acc: 67.23%\n",
      "Epoch 28/150\n",
      "Training Loss: 0.7572, Training Acc: 73.10%\n",
      "Validation Loss: 0.9817, Validation Acc: 66.73%\n",
      "Epoch 29/150\n",
      "Training Loss: 0.7887, Training Acc: 71.80%\n",
      "Validation Loss: 0.9621, Validation Acc: 67.20%\n",
      "Epoch 30/150\n",
      "Training Loss: 0.7635, Training Acc: 72.48%\n",
      "Validation Loss: 0.9543, Validation Acc: 68.24%\n",
      "Epoch 31/150\n",
      "Training Loss: 0.7824, Training Acc: 72.49%\n",
      "Validation Loss: 0.9573, Validation Acc: 68.30%\n",
      "Epoch 32/150\n",
      "Training Loss: 0.7796, Training Acc: 72.14%\n",
      "Validation Loss: 0.9751, Validation Acc: 67.97%\n",
      "Epoch 33/150\n",
      "Training Loss: 0.7725, Training Acc: 72.44%\n",
      "Validation Loss: 1.0352, Validation Acc: 63.70%\n",
      "Epoch 34/150\n",
      "Training Loss: 0.7786, Training Acc: 72.22%\n",
      "Validation Loss: 0.9458, Validation Acc: 68.65%\n",
      "Epoch 35/150\n",
      "Training Loss: 0.7710, Training Acc: 72.43%\n",
      "Validation Loss: 0.9475, Validation Acc: 68.83%\n",
      "Epoch 36/150\n",
      "Training Loss: 0.7668, Training Acc: 72.57%\n",
      "Validation Loss: 0.9643, Validation Acc: 68.21%\n",
      "Epoch 37/150\n",
      "Training Loss: 0.7698, Training Acc: 72.71%\n",
      "Validation Loss: 1.0085, Validation Acc: 65.48%\n",
      "Epoch 38/150\n",
      "Training Loss: 0.7656, Training Acc: 72.76%\n",
      "Validation Loss: 0.9545, Validation Acc: 67.23%\n",
      "Epoch 39/150\n",
      "Training Loss: 0.7468, Training Acc: 73.36%\n",
      "Validation Loss: 0.9888, Validation Acc: 68.03%\n",
      "Epoch 40/150\n",
      "Training Loss: 0.7630, Training Acc: 72.58%\n",
      "Validation Loss: 1.0003, Validation Acc: 66.81%\n",
      "Epoch 41/150\n",
      "Training Loss: 0.7441, Training Acc: 73.12%\n",
      "Validation Loss: 0.9237, Validation Acc: 68.89%\n",
      "Epoch 42/150\n",
      "Training Loss: 0.7470, Training Acc: 73.65%\n",
      "Validation Loss: 0.9646, Validation Acc: 67.76%\n",
      "Epoch 43/150\n",
      "Training Loss: 0.7451, Training Acc: 72.76%\n",
      "Validation Loss: 0.9559, Validation Acc: 69.04%\n",
      "Epoch 44/150\n",
      "Training Loss: 0.7491, Training Acc: 73.36%\n",
      "Validation Loss: 0.9412, Validation Acc: 69.40%\n",
      "Epoch 45/150\n",
      "Training Loss: 0.7453, Training Acc: 72.84%\n",
      "Validation Loss: 0.9231, Validation Acc: 69.69%\n",
      "Epoch 46/150\n",
      "Training Loss: 0.7320, Training Acc: 73.48%\n",
      "Validation Loss: 0.9160, Validation Acc: 67.91%\n",
      "Epoch 47/150\n",
      "Training Loss: 0.7252, Training Acc: 74.29%\n",
      "Validation Loss: 0.9553, Validation Acc: 67.82%\n",
      "Epoch 48/150\n",
      "Training Loss: 0.7295, Training Acc: 74.12%\n",
      "Validation Loss: 0.9680, Validation Acc: 68.42%\n",
      "Epoch 49/150\n",
      "Training Loss: 0.7568, Training Acc: 72.82%\n",
      "Validation Loss: 0.9744, Validation Acc: 66.87%\n",
      "Epoch 50/150\n",
      "Training Loss: 0.7533, Training Acc: 73.20%\n",
      "Validation Loss: 0.9231, Validation Acc: 69.10%\n",
      "Epoch 51/150\n",
      "Training Loss: 0.7363, Training Acc: 74.02%\n",
      "Validation Loss: 0.8964, Validation Acc: 70.85%\n",
      "Epoch 52/150\n",
      "Training Loss: 0.7281, Training Acc: 73.85%\n",
      "Validation Loss: 1.0258, Validation Acc: 63.91%\n",
      "Epoch 53/150\n",
      "Training Loss: 0.7332, Training Acc: 74.17%\n",
      "Validation Loss: 0.9596, Validation Acc: 68.48%\n",
      "Epoch 54/150\n",
      "Training Loss: 0.7335, Training Acc: 73.43%\n",
      "Validation Loss: 0.9632, Validation Acc: 70.67%\n",
      "Epoch 55/150\n",
      "Training Loss: 0.7197, Training Acc: 74.14%\n",
      "Validation Loss: 0.9360, Validation Acc: 68.95%\n",
      "Epoch 56/150\n",
      "Training Loss: 0.7181, Training Acc: 74.17%\n",
      "Validation Loss: 0.9883, Validation Acc: 66.64%\n",
      "Epoch 57/150\n",
      "Training Loss: 0.7216, Training Acc: 73.68%\n",
      "Validation Loss: 0.9600, Validation Acc: 66.90%\n",
      "Epoch 58/150\n",
      "Training Loss: 0.7243, Training Acc: 74.16%\n",
      "Validation Loss: 0.9616, Validation Acc: 69.54%\n",
      "Epoch 59/150\n",
      "Training Loss: 0.7235, Training Acc: 74.47%\n",
      "Validation Loss: 0.9393, Validation Acc: 69.66%\n",
      "Epoch 60/150\n",
      "Training Loss: 0.7170, Training Acc: 73.99%\n",
      "Validation Loss: 0.9663, Validation Acc: 68.65%\n",
      "Epoch 61/150\n",
      "Training Loss: 0.7214, Training Acc: 73.92%\n",
      "Validation Loss: 0.9836, Validation Acc: 67.41%\n",
      "Epoch 62/150\n",
      "Training Loss: 0.7238, Training Acc: 73.99%\n",
      "Validation Loss: 0.9953, Validation Acc: 67.11%\n",
      "Epoch 63/150\n",
      "Training Loss: 0.7380, Training Acc: 73.79%\n",
      "Validation Loss: 1.0224, Validation Acc: 66.07%\n",
      "Epoch 64/150\n",
      "Training Loss: 0.7361, Training Acc: 72.95%\n",
      "Validation Loss: 0.9132, Validation Acc: 69.78%\n",
      "Epoch 65/150\n",
      "Training Loss: 0.7022, Training Acc: 74.86%\n",
      "Validation Loss: 0.9048, Validation Acc: 70.11%\n",
      "Epoch 66/150\n",
      "Training Loss: 0.7104, Training Acc: 74.54%\n",
      "Validation Loss: 0.9403, Validation Acc: 68.71%\n",
      "Epoch 67/150\n",
      "Training Loss: 0.7088, Training Acc: 74.68%\n",
      "Validation Loss: 0.9324, Validation Acc: 69.42%\n",
      "Epoch 68/150\n",
      "Training Loss: 0.7017, Training Acc: 74.48%\n",
      "Validation Loss: 1.0182, Validation Acc: 66.01%\n",
      "Epoch 69/150\n",
      "Training Loss: 0.7194, Training Acc: 73.99%\n",
      "Validation Loss: 0.9775, Validation Acc: 69.01%\n",
      "Epoch 70/150\n",
      "Training Loss: 0.7247, Training Acc: 74.13%\n",
      "Validation Loss: 0.9897, Validation Acc: 67.35%\n",
      "Epoch 71/150\n",
      "Training Loss: 0.7100, Training Acc: 74.48%\n",
      "Validation Loss: 0.9873, Validation Acc: 68.80%\n",
      "Epoch 72/150\n",
      "Training Loss: 0.6984, Training Acc: 75.04%\n",
      "Validation Loss: 0.9714, Validation Acc: 66.79%\n",
      "Epoch 73/150\n",
      "Training Loss: 0.7033, Training Acc: 75.25%\n",
      "Validation Loss: 1.0174, Validation Acc: 66.67%\n",
      "Epoch 74/150\n",
      "Training Loss: 0.7303, Training Acc: 73.64%\n",
      "Validation Loss: 0.9458, Validation Acc: 67.59%\n",
      "Epoch 75/150\n",
      "Training Loss: 0.7034, Training Acc: 74.80%\n",
      "Validation Loss: 0.9131, Validation Acc: 69.69%\n",
      "Epoch 76/150\n",
      "Training Loss: 0.7092, Training Acc: 74.55%\n",
      "Validation Loss: 0.9864, Validation Acc: 67.44%\n",
      "Epoch 77/150\n",
      "Training Loss: 0.7152, Training Acc: 74.44%\n",
      "Validation Loss: 0.9553, Validation Acc: 67.70%\n",
      "Epoch 78/150\n",
      "Training Loss: 0.7119, Training Acc: 74.38%\n",
      "Validation Loss: 0.9469, Validation Acc: 69.81%\n",
      "Epoch 79/150\n",
      "Training Loss: 0.7067, Training Acc: 74.56%\n",
      "Validation Loss: 0.9694, Validation Acc: 68.68%\n",
      "Epoch 80/150\n",
      "Training Loss: 0.7087, Training Acc: 74.58%\n",
      "Validation Loss: 0.9339, Validation Acc: 69.51%\n",
      "Epoch 81/150\n",
      "Training Loss: 0.7146, Training Acc: 73.72%\n",
      "Validation Loss: 0.9794, Validation Acc: 66.81%\n",
      "Epoch 82/150\n",
      "Training Loss: 0.7107, Training Acc: 74.36%\n",
      "Validation Loss: 0.9620, Validation Acc: 68.89%\n",
      "Epoch 83/150\n",
      "Training Loss: 0.7161, Training Acc: 74.51%\n",
      "Validation Loss: 0.9629, Validation Acc: 68.80%\n",
      "Epoch 84/150\n",
      "Training Loss: 0.6841, Training Acc: 75.40%\n",
      "Validation Loss: 0.9544, Validation Acc: 69.19%\n",
      "Epoch 85/150\n",
      "Training Loss: 0.7141, Training Acc: 74.34%\n",
      "Validation Loss: 0.9598, Validation Acc: 68.33%\n",
      "Epoch 86/150\n",
      "Training Loss: 0.7008, Training Acc: 75.28%\n",
      "Validation Loss: 0.9539, Validation Acc: 68.65%\n",
      "Epoch 87/150\n",
      "Training Loss: 0.7060, Training Acc: 74.14%\n",
      "Validation Loss: 0.9562, Validation Acc: 69.28%\n",
      "Epoch 88/150\n",
      "Training Loss: 0.7055, Training Acc: 74.31%\n",
      "Validation Loss: 0.9691, Validation Acc: 68.68%\n",
      "Epoch 89/150\n",
      "Training Loss: 0.6901, Training Acc: 74.96%\n",
      "Validation Loss: 0.9822, Validation Acc: 68.62%\n",
      "Epoch 90/150\n",
      "Training Loss: 0.7091, Training Acc: 74.41%\n",
      "Validation Loss: 0.9180, Validation Acc: 71.44%\n",
      "Epoch 91/150\n",
      "Training Loss: 0.6904, Training Acc: 74.66%\n",
      "Validation Loss: 0.8968, Validation Acc: 71.80%\n",
      "Epoch 92/150\n",
      "Training Loss: 0.6813, Training Acc: 75.21%\n",
      "Validation Loss: 0.8988, Validation Acc: 70.85%\n",
      "Epoch 93/150\n",
      "Training Loss: 0.6778, Training Acc: 75.68%\n",
      "Validation Loss: 0.9495, Validation Acc: 68.71%\n",
      "Epoch 94/150\n",
      "Training Loss: 0.6840, Training Acc: 75.06%\n",
      "Validation Loss: 0.9136, Validation Acc: 69.60%\n",
      "Epoch 95/150\n",
      "Training Loss: 0.6950, Training Acc: 74.89%\n",
      "Validation Loss: 0.9656, Validation Acc: 68.83%\n",
      "Epoch 96/150\n",
      "Training Loss: 0.6936, Training Acc: 74.73%\n",
      "Validation Loss: 0.9746, Validation Acc: 68.59%\n",
      "Epoch 97/150\n",
      "Training Loss: 0.6974, Training Acc: 75.11%\n",
      "Validation Loss: 0.9169, Validation Acc: 69.96%\n",
      "Epoch 98/150\n",
      "Training Loss: 0.6935, Training Acc: 74.91%\n",
      "Validation Loss: 0.9877, Validation Acc: 66.22%\n",
      "Epoch 99/150\n",
      "Training Loss: 0.6829, Training Acc: 75.70%\n",
      "Validation Loss: 0.9507, Validation Acc: 70.20%\n",
      "Epoch 100/150\n",
      "Training Loss: 0.6735, Training Acc: 75.87%\n",
      "Validation Loss: 0.9785, Validation Acc: 70.02%\n",
      "Epoch 101/150\n",
      "Training Loss: 0.6815, Training Acc: 75.54%\n",
      "Validation Loss: 0.9233, Validation Acc: 70.91%\n",
      "Epoch 102/150\n",
      "Training Loss: 0.7032, Training Acc: 75.29%\n",
      "Validation Loss: 1.0121, Validation Acc: 66.70%\n",
      "Epoch 103/150\n",
      "Training Loss: 0.6766, Training Acc: 75.97%\n",
      "Validation Loss: 0.9706, Validation Acc: 69.01%\n",
      "Epoch 104/150\n",
      "Training Loss: 0.6795, Training Acc: 75.26%\n",
      "Validation Loss: 0.9589, Validation Acc: 69.57%\n",
      "Epoch 105/150\n",
      "Training Loss: 0.6721, Training Acc: 75.63%\n",
      "Validation Loss: 0.9392, Validation Acc: 70.02%\n",
      "Epoch 106/150\n",
      "Training Loss: 0.6785, Training Acc: 75.58%\n",
      "Validation Loss: 0.9158, Validation Acc: 69.57%\n",
      "Epoch 107/150\n",
      "Training Loss: 0.6861, Training Acc: 75.32%\n",
      "Validation Loss: 0.9315, Validation Acc: 69.60%\n",
      "Epoch 108/150\n",
      "Training Loss: 0.6930, Training Acc: 74.92%\n",
      "Validation Loss: 0.9647, Validation Acc: 69.60%\n",
      "Epoch 109/150\n",
      "Training Loss: 0.6800, Training Acc: 75.54%\n",
      "Validation Loss: 0.9584, Validation Acc: 67.62%\n",
      "Epoch 110/150\n",
      "Training Loss: 0.6851, Training Acc: 75.59%\n",
      "Validation Loss: 0.9044, Validation Acc: 71.59%\n",
      "Epoch 111/150\n",
      "Training Loss: 0.6817, Training Acc: 75.13%\n",
      "Validation Loss: 0.9219, Validation Acc: 71.89%\n",
      "Epoch 112/150\n",
      "Training Loss: 0.6698, Training Acc: 75.90%\n",
      "Validation Loss: 0.9520, Validation Acc: 69.45%\n",
      "Epoch 113/150\n",
      "Training Loss: 0.6812, Training Acc: 75.34%\n",
      "Validation Loss: 0.9684, Validation Acc: 69.96%\n",
      "Epoch 114/150\n",
      "Training Loss: 0.6951, Training Acc: 74.70%\n",
      "Validation Loss: 0.9733, Validation Acc: 70.02%\n",
      "Epoch 115/150\n",
      "Training Loss: 0.6719, Training Acc: 75.83%\n",
      "Validation Loss: 0.9756, Validation Acc: 69.25%\n",
      "Epoch 116/150\n",
      "Training Loss: 0.6790, Training Acc: 75.22%\n",
      "Validation Loss: 0.9506, Validation Acc: 70.37%\n",
      "Epoch 117/150\n",
      "Training Loss: 0.6958, Training Acc: 74.97%\n",
      "Validation Loss: 0.9344, Validation Acc: 70.97%\n",
      "Epoch 118/150\n",
      "Training Loss: 0.6912, Training Acc: 75.11%\n",
      "Validation Loss: 0.9491, Validation Acc: 69.51%\n",
      "Epoch 119/150\n",
      "Training Loss: 0.6771, Training Acc: 75.33%\n",
      "Validation Loss: 0.8965, Validation Acc: 71.86%\n",
      "Epoch 120/150\n",
      "Training Loss: 0.6731, Training Acc: 75.96%\n",
      "Validation Loss: 0.9429, Validation Acc: 71.35%\n",
      "Epoch 121/150\n",
      "Training Loss: 0.6865, Training Acc: 75.46%\n",
      "Validation Loss: 0.8879, Validation Acc: 71.89%\n",
      "Epoch 122/150\n",
      "Training Loss: 0.6774, Training Acc: 75.19%\n",
      "Validation Loss: 1.0127, Validation Acc: 68.09%\n",
      "Epoch 123/150\n",
      "Training Loss: 0.6827, Training Acc: 75.49%\n",
      "Validation Loss: 0.9925, Validation Acc: 67.65%\n",
      "Epoch 124/150\n",
      "Training Loss: 0.6825, Training Acc: 75.47%\n",
      "Validation Loss: 0.9067, Validation Acc: 71.62%\n",
      "Epoch 125/150\n",
      "Training Loss: 0.6765, Training Acc: 75.59%\n",
      "Validation Loss: 0.9734, Validation Acc: 70.58%\n",
      "Epoch 126/150\n",
      "Training Loss: 0.6809, Training Acc: 75.49%\n",
      "Validation Loss: 0.9670, Validation Acc: 69.60%\n",
      "Epoch 127/150\n",
      "Training Loss: 0.6841, Training Acc: 74.84%\n",
      "Validation Loss: 0.9757, Validation Acc: 69.42%\n",
      "Epoch 128/150\n",
      "Training Loss: 0.6804, Training Acc: 75.65%\n",
      "Validation Loss: 0.9527, Validation Acc: 70.91%\n",
      "Epoch 129/150\n",
      "Training Loss: 0.6663, Training Acc: 76.33%\n",
      "Validation Loss: 0.9497, Validation Acc: 70.11%\n",
      "Epoch 130/150\n",
      "Training Loss: 0.6773, Training Acc: 75.98%\n",
      "Validation Loss: 0.9414, Validation Acc: 70.55%\n",
      "Epoch 131/150\n",
      "Training Loss: 0.6686, Training Acc: 75.81%\n",
      "Validation Loss: 0.9985, Validation Acc: 68.27%\n",
      "Epoch 132/150\n",
      "Training Loss: 0.6715, Training Acc: 76.04%\n",
      "Validation Loss: 0.9404, Validation Acc: 70.14%\n",
      "Epoch 133/150\n",
      "Training Loss: 0.6714, Training Acc: 75.68%\n",
      "Validation Loss: 0.9575, Validation Acc: 69.81%\n",
      "Epoch 134/150\n",
      "Training Loss: 0.6740, Training Acc: 75.62%\n",
      "Validation Loss: 0.9186, Validation Acc: 70.55%\n",
      "Epoch 135/150\n",
      "Training Loss: 0.6619, Training Acc: 76.60%\n",
      "Validation Loss: 0.9329, Validation Acc: 71.26%\n",
      "Epoch 136/150\n",
      "Training Loss: 0.6769, Training Acc: 75.83%\n",
      "Validation Loss: 0.9320, Validation Acc: 69.69%\n",
      "Epoch 137/150\n",
      "Training Loss: 0.6758, Training Acc: 75.68%\n",
      "Validation Loss: 0.9462, Validation Acc: 68.77%\n",
      "Epoch 138/150\n",
      "Training Loss: 0.6735, Training Acc: 75.55%\n",
      "Validation Loss: 0.9324, Validation Acc: 70.88%\n",
      "Epoch 139/150\n",
      "Training Loss: 0.6797, Training Acc: 75.69%\n",
      "Validation Loss: 0.9856, Validation Acc: 68.86%\n",
      "Epoch 140/150\n",
      "Training Loss: 0.6646, Training Acc: 76.39%\n",
      "Validation Loss: 0.9547, Validation Acc: 70.49%\n",
      "Epoch 141/150\n",
      "Training Loss: 0.6831, Training Acc: 75.95%\n",
      "Validation Loss: 0.9604, Validation Acc: 69.96%\n",
      "Epoch 142/150\n",
      "Training Loss: 0.6579, Training Acc: 76.21%\n",
      "Validation Loss: 0.9280, Validation Acc: 70.79%\n",
      "Epoch 143/150\n",
      "Training Loss: 0.6742, Training Acc: 75.39%\n",
      "Validation Loss: 0.9814, Validation Acc: 69.13%\n",
      "Epoch 144/150\n",
      "Training Loss: 0.6563, Training Acc: 76.67%\n",
      "Validation Loss: 0.9660, Validation Acc: 70.82%\n",
      "Epoch 145/150\n",
      "Training Loss: 0.6637, Training Acc: 76.56%\n",
      "Validation Loss: 0.9535, Validation Acc: 70.23%\n",
      "Epoch 146/150\n",
      "Training Loss: 0.6706, Training Acc: 75.72%\n",
      "Validation Loss: 0.9641, Validation Acc: 70.26%\n",
      "Epoch 147/150\n",
      "Training Loss: 0.6856, Training Acc: 75.15%\n",
      "Validation Loss: 0.9693, Validation Acc: 70.11%\n",
      "Epoch 148/150\n",
      "Training Loss: 0.6647, Training Acc: 75.54%\n",
      "Validation Loss: 0.9495, Validation Acc: 71.32%\n",
      "Epoch 149/150\n",
      "Training Loss: 0.6610, Training Acc: 76.09%\n",
      "Validation Loss: 0.9090, Validation Acc: 71.03%\n",
      "Epoch 150/150\n",
      "Training Loss: 0.6430, Training Acc: 77.01%\n",
      "Validation Loss: 0.9285, Validation Acc: 70.88%\n",
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.classification_keypoint import AngleLSTMNet, AngleFeatureExtractor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize angle feature extractor\n",
    "angle_extractor = AngleFeatureExtractor()\n",
    "\n",
    "# Load the pre-split training and testing data\n",
    "train_data = pd.read_csv('/Users/jashtandel/SEM6/Approach2/datasets/train_action_pose_keypoint.csv')\n",
    "test_data = pd.read_csv('/Users/jashtandel/SEM6/Approach2/datasets/test_action_pose_keypoint.csv')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
    "test_data['label'] = label_encoder.transform(test_data['label'])\n",
    "\n",
    "# Extract angular features from keypoints\n",
    "def extract_angular_features(data):\n",
    "    keypoints = data.iloc[:, 2:].values  # Select only keypoint columns\n",
    "    angles_list = []\n",
    "    for keypoint_row in keypoints:\n",
    "        angles = angle_extractor.calculate_angles(keypoint_row)\n",
    "        angles_list.append(angles)\n",
    "    return np.array(angles_list)\n",
    "\n",
    "# Process training and testing data\n",
    "X_train = extract_angular_features(train_data)\n",
    "y_train = train_data['label'].values\n",
    "X_test = extract_angular_features(test_data)\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# Reshape for LSTM (batch, sequence_length, features)\n",
    "X_train = X_train.reshape(-1, 1, 8)  # 8 angular features\n",
    "X_test = X_test.reshape(-1, 1, 8)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 8  # Number of angular features\n",
    "hidden_size = 128  # Increased from 64\n",
    "num_layers = 3  # Increased from 2\n",
    "num_classes = len(label_encoder.classes_)\n",
    "lstm_dropout = 0.3\n",
    "fc_dropout = 0.5\n",
    "weight_decay = 1e-5\n",
    "learning_rate = 0.001\n",
    "num_epochs = 150\n",
    "patience = 10\n",
    "save_path = '/Users/jashtandel/SEM6/YoloV8-Pose-Keypoint-Classification-master/models/HAAD_Pose_Angle.pt'\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = AngleLSTMNet(input_size=input_size, hidden_size=hidden_size,\n",
    "                     num_layers=num_layers, num_classes=num_classes,\n",
    "                     lstm_dropout=lstm_dropout, fc_dropout=fc_dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, patience, save_path):\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    best_model_state = None\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {epoch_loss:.4f}, Training Acc: {train_acc:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.2f}%')\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        if early_stopping(val_loss):\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model_state is not None:\n",
    "        torch.save(best_model_state, save_path)\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, num_epochs, patience, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
